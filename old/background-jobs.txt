Background Jobs / Workers
===============

Queueing is the key to building truly scalable web apps. Don't do any heavy
lifting in the web processes (Mongrel/Thin); instead, put things on a queue
and do the work in a background process. This ensures that web requests can
always return immediately.

A good rule of thumb is to avoid web requests which run longer than 500ms.
If you find that your app has requests which are take one, two, or more
seconds to complete, then you should consider using background jobs instead.

Introduction to job queues
--------------------------

Fetching data from remote APIs, reading RSS feeds, resizing images, and
uploading data to S3 are all examples of tasks that should be processed as
background jobs. The web hit that requests the job places it in queue and
returns to the client immediately. The client can then poll for updates to
see when their job is complete.

Consider the example of a web-based RSS reader. An app like this will have
a form where users can submit a new feed URL to be read. After a delay, the
user will be taken to a page where they can see the contents of the feed. A
simple but non-scalable way to do this would be to run it directly inside
the web request, like this:

    :::ruby
    class FeedsController
      def create
        feed = Feed.create! params
        feed.fetch
        redirect_to feed_url(feed)
      end
    end

The fetch action in the model is the potentially heavy part of this:

    :::ruby
    class Feed < ActiveRecord::Base
      def fetch
        xml = RestClient.get url
        # ... do read and parse the feed, putting the results in the database
      end
    end

In the example, `feed.fetch` will go out to the network and pull down the
data from the feed, inserting the results into the database. Sometimes this
may happen in as little as a few hundred milliseconds, other times it may
take several seconds. If the feed's server is down, it could hang for 30
seconds or more until the request times out. Tying up your app's dyno during
this time prevents it from handling other requests, and leaves your user
hanging, wondering if your app is working properly. This is okay for a
single user, but as soon as your app has multiple simultaneous users, you'll
find that response times become more and more inconsistent.

A better approach is to add the work-to-be-done to a queue:

    :::ruby
    class FeedController
      def create
        feed = Feed.create! params
        Delayed::Job.enqueue feed
        redirect_to url_for(feed)
      end
    end

One or more worker processes, running separately (not serving web requests)
will read items off the queue one by one and do the work asynchronously.  The
results will be placed in the database when finished.

Handling long-running work with background workers has many benefits.  It
avoids tying up your web dynos, preventing them from serving other requests,
and keeping your site snappy.  You can monitor and control the worker
processes independently, and manage and introspect the queue to manage your
site's load.  And the user experience for those visiting your site will be
greatly improved when they get an immediate response to any page viewed,
even if that response is only to say that their request has been received
and is currently being processed.

Background Jobs on Heroku
-------------------------

Heroku supports multiple [Delayed Job](delayed-job) workers.  Workers are charged at the same rate as Dynos: $0.05 per hour, prorated to the second.  Unlike Dynos, Workers are starting with the first worker.   For example, an application with 3 workers for 3 hours will be charged $0.15 for each hour the workers are running.

See the [docs](delayed-job) to add it to your application.


